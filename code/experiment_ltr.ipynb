{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from attack import (\n",
    "    reconstruct_interactions,\n",
    ")\n",
    "from dataset import (\n",
    "    LearningToRankDataset,\n",
    ")\n",
    "from more_itertools import grouper\n",
    "from ranker import (\n",
    "    LinearPDGDRanker,\n",
    "    Neural1LayerPDGDRanker,\n",
    "    Neural2LayerPDGDRanker,\n",
    ")\n",
    "from scipy.stats import ks_2samp\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import (\n",
    "    CascadeClickModel,\n",
    "    Metrics,\n",
    "    apply_gaussian_mechanism,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/MQ2008/Fold1/test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2874it [00:00, 39059.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def set_seed():\n",
    "    torch.manual_seed(2023)\n",
    "    random.seed(2023)\n",
    "    np.random.seed(2023)\n",
    "\n",
    "# Make sure to normalize if using MSLR\n",
    "data = LearningToRankDataset(\"../dataset/MQ2008/Fold1/test.txt\", normalize=False)\n",
    "num_features = data.get_num_features()\n",
    "\n",
    "models = {\n",
    "    \"linear_pdgd\": LinearPDGDRanker(num_features),\n",
    "    # \"neural_4_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=4),\n",
    "    # \"neural_8_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=8),\n",
    "    # \"neural_16_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=16),\n",
    "    # \"neural_4_2_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=4, hidden_size2=2\n",
    "    # ),\n",
    "    # \"neural_8_4_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=8, hidden_size2=4\n",
    "    # ),\n",
    "    \"neural_16_8_pdgd\": Neural2LayerPDGDRanker(\n",
    "        num_features, hidden_size=16, hidden_size2=8\n",
    "    ),\n",
    "}\n",
    "\n",
    "click_models = {\n",
    "    # \"perfect\": CascadeClickModel(prob_click=[0.0, 0.5, 1.0], prob_stop=[0.0, 0.0, 0.0]),\n",
    "    \"navigational\": CascadeClickModel(\n",
    "        prob_click=[0.05, 0.5, 0.95], prob_stop=[0.2, 0.5, 0.9]\n",
    "    ),\n",
    "    \"informational\": CascadeClickModel(\n",
    "        prob_click=[0.4, 0.7, 0.9], prob_stop=[0.1, 0.3, 0.5]\n",
    "    ),\n",
    "}\n",
    "\n",
    "# MSLR Click Model\n",
    "# click_models = {\n",
    "#     \"perfect\": CascadeClickModel(\n",
    "#         prob_click=[0.0, 0.2, 0.4, 0.8, 1.0], prob_stop=[0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "#     ),\n",
    "#     \"navigational\": CascadeClickModel(\n",
    "#         prob_click=[0.05, 0.3, 0.5, 0.7, 0.95], prob_stop=[0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "#     ),\n",
    "#     \"informational\": CascadeClickModel(\n",
    "#         prob_click=[0.4, 0.6, 0.7, 0.8, 0.9], prob_stop=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#     ),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:11<00:00, 31.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Simulation for LTR\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_sim_round = 10\n",
    "num_features = 10\n",
    "num_data = 100\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "models = {\n",
    "    \"linear_pdgd\": LinearPDGDRanker(num_features),\n",
    "    # \"neural_1_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=5),\n",
    "    # \"neural_2_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=4, hidden_size2=2\n",
    "    # ),\n",
    "}\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    features = torch.rand(num_data, num_features) * 2 - 1\n",
    "    interactions = torch.randint(0, 2, (num_data,))\n",
    "    while interactions.sum() == 0:\n",
    "        interactions = torch.randint(0, 2, (num_data,))\n",
    "    \n",
    "    ranking = list(range(num_data))\n",
    "    random.shuffle(ranking)\n",
    "    ranking = torch.LongTensor(ranking)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        params = model.gen_params()\n",
    "        log_pos_bias_weight = model.calc_log_pos_bias_weight(\n",
    "            ranking, model.forward_multiple(params, features), num_data\n",
    "        )\n",
    "        \n",
    "        target = model.grad(\n",
    "            params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "            log_pos_bias_weight=log_pos_bias_weight,\n",
    "        )\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: model.grad(\n",
    "                params, features, ranking, I, log_pos_bias_weight=log_pos_bias_weight\n",
    "            ),\n",
    "            target,\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(model_name, interactions, preds, preds_raw=preds_raw)\n",
    "\n",
    "    # Data manipulation\n",
    "    if num_data > num_features:\n",
    "        num_new_features = num_data - num_features\n",
    "        new_features = torch.rand(num_data, num_new_features)\n",
    "        features = torch.cat([features, new_features], dim=1)\n",
    "\n",
    "        model = LinearPDGDRanker(num_features + num_new_features)\n",
    "        params = model.gen_params()\n",
    "        log_pos_bias_weight = model.calc_log_pos_bias_weight(\n",
    "            ranking, model.forward_multiple(params, features), num_data\n",
    "        )\n",
    "        \n",
    "        target = model.grad(\n",
    "            params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "            log_pos_bias_weight=log_pos_bias_weight,\n",
    "        )\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: model.grad(\n",
    "                params, features, ranking, I, log_pos_bias_weight=log_pos_bias_weight\n",
    "            ),\n",
    "            target,\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(model_name + \"_DM\", interactions, preds, preds_raw=preds_raw)\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: random queries\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [8]\n",
    "num_train_query = 3\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1.0\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, grouped_data, click_model):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    target_ind = random.sample(range(len(grouped_train_data)), num_train_query)\n",
    "\n",
    "    target = train(\n",
    "        model,\n",
    "        params,\n",
    "        [grouped_train_data[i] for i in target_ind],\n",
    "        local_lr,\n",
    "    )\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: train(\n",
    "            model,\n",
    "            params,\n",
    "            [\n",
    "                (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "            ],\n",
    "            local_lr,\n",
    "        ),\n",
    "        target,\n",
    "        indices[-1][1],\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "    interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "    return (interactions, preds, preds_raw, [indices[i] for i in target_ind])\n",
    "\n",
    "\n",
    "for num_query in num_query_per_user:\n",
    "    print(f\"Num query: {num_query}\")\n",
    "    for _ in tqdm(range(num_sim_round)):\n",
    "        for qids in tqdm(\n",
    "            grouper(data.get_all_query_ids(), num_query, incomplete=\"ignore\"),\n",
    "            total=len(data.get_all_query_ids()) // num_query,\n",
    "        ):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    interactions, preds, preds_raw, indices = simulate_attack(\n",
    "                        model, grouped_data, click_model\n",
    "                    )\n",
    "\n",
    "                    metrics.update(\n",
    "                        f\"{model_name}_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        preds,\n",
    "                        preds_raw=preds_raw,\n",
    "                    )\n",
    "\n",
    "                    actual_interactions = []\n",
    "                    actual_preds = []\n",
    "                    actual_preds_raw = []\n",
    "                    for (i1, i2) in indices:\n",
    "                        actual_interactions += interactions[i1:i2]\n",
    "                        actual_preds += preds[i1:i2]\n",
    "                        actual_preds_raw += preds_raw[i1:i2]\n",
    "                    \n",
    "                    metrics.update(\n",
    "                        f\"{model_name}_{click_model_name}_{num_query}_query_actual\",\n",
    "                        actual_interactions,\n",
    "                        actual_preds,\n",
    "                        preds_raw=actual_preds_raw,\n",
    "                    )\n",
    "\n",
    "                    # Random guess\n",
    "                    random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                    random_preds = random_preds_raw.round()\n",
    "                    metrics.update(\n",
    "                        f\"random_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        random_preds,\n",
    "                        preds_raw=random_preds_raw,\n",
    "                    )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: multiple queries, random order, DP\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [1, 4, 8, 12, 16]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "epsilons = [1.0, 10.0, 100.0, math.inf]\n",
    "delta = 1e-08\n",
    "sensitivity = 4.0\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, model_name, grouped_data, click_model, epsilons, click_model_name, num_query):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        if len(relevances) == 1:\n",
    "            continue\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    if len(grouped_train_data) < 1:\n",
    "        return\n",
    "\n",
    "    raw_target = train(\n",
    "        model,\n",
    "        params,\n",
    "        random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "        local_lr,\n",
    "    )\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        target = (apply_gaussian_mechanism(raw_target, epsilon, delta, sensitivity) - params) / local_lr\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: (train(\n",
    "                model,\n",
    "                params,\n",
    "                [\n",
    "                    (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                    for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "                ],\n",
    "                local_lr,\n",
    "            ) - params) / local_lr,\n",
    "            target,\n",
    "            indices[-1][1],\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "\n",
    "        metrics.update(\n",
    "            f\"{model_name}_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "        # Random guess\n",
    "        random_preds_raw = torch.rand(preds_raw.shape)\n",
    "        random_preds = random_preds_raw.round()\n",
    "        metrics.update(\n",
    "            f\"random_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "            interactions,\n",
    "            random_preds,\n",
    "            preds_raw=random_preds_raw,\n",
    "        )\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    query_ids = data.get_all_query_ids()\n",
    "    query_ids = random.sample(query_ids, len(query_ids))    \n",
    "\n",
    "    for num_query in num_query_per_user:\n",
    "        print(\"Num query\", num_query)\n",
    "        for qids in tqdm(grouper(query_ids, num_query, incomplete=\"ignore\"), total=len(query_ids)//num_query):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    simulate_attack(model, model_name, grouped_data, click_model, epsilons, click_model_name, num_query)\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())\n",
    "# metrics.save(\"../output/ltr_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe()\n",
    "dp[\"eps\"] = dp.index.to_series().apply(lambda name: float(name.split(\"_\")[name.split(\"_\").index(\"eps\") + 1]))\n",
    "dp[\"model\"] = dp.index.to_series().apply(lambda name: \"_\".join(name.split(\"_\")[:name.split(\"_\").index(\"eps\")]))\n",
    "dp = dp.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "for model in dp[(\"model\", \"\")].unique().tolist():\n",
    "    df = dp[dp[(\"model\", \"\")] == model].sort_values(by=[\"eps\"])\n",
    "    ax[0].plot(df[(\"eps\", \"\")].astype(str), df[(\"auc\", \"mean\")], 'o-', label=model)\n",
    "    ax[1].plot(df[(\"eps\", \"\")].astype(str), df[(\"auc-pr\", \"mean\")], 'o-', label=model)\n",
    "    ax[0].set_xticks(df[(\"eps\", \"\")].astype(str))\n",
    "    ax[1].set_xticks(df[(\"eps\", \"\")].astype(str))\n",
    "\n",
    "ax[0].set_ylabel(\"auc\")\n",
    "ax[1].set_ylabel(\"auc-pr\")\n",
    "\n",
    "ax[0].legend()\n",
    "fig.set_figwidth(10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models.keys():\n",
    "    print(f\"***** Model {model_name} *****\")\n",
    "    for epsilon in epsilons:\n",
    "        for num_query in num_query_per_user:\n",
    "            print(f\"Epsilon {epsilon}, num query {num_query}\")\n",
    "            for click_model in click_models.keys():\n",
    "                print(f\"{click_model} AUC p-value:\", ks_2samp(\n",
    "                    metrics.df[metrics.df[\"name\"] == f\"{model_name}_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc\"],\n",
    "                    metrics.df[metrics.df[\"name\"] == f\"random_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc\"],\n",
    "                    alternative=\"less\",\n",
    "                ).pvalue)\n",
    "                print(f\"{click_model} AUC-PR p-value:\", ks_2samp(\n",
    "                    metrics.df[metrics.df[\"name\"] == f\"{model_name}_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc-pr\"],\n",
    "                    metrics.df[metrics.df[\"name\"] == f\"random_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc-pr\"],\n",
    "                    alternative=\"less\",\n",
    "                ).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2644d183b2b4296853640b5f2374ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num query 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb2519ca4cb4ce3a86e3d8d8ca04dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    auc                                                                       auc-pr                                                                      \n",
      "                                                  count      mean       std       min       25%       50%       75%       max  count      mean       std       min       25%       50%       75%       max\n",
      "name                                                                                                                                                                                                      \n",
      "linear_pdgd_informational_16_query_prune_0.5        9.0  0.577908  0.060082  0.508932  0.537276  0.559982  0.612275  0.702500    9.0  0.432120  0.071327  0.353251  0.384427  0.415891  0.440396  0.581530\n",
      "linear_pdgd_navigational_16_query_prune_0.5         9.0  0.637560  0.041869  0.566116  0.613852  0.648404  0.661417  0.689840    9.0  0.233984  0.056306  0.168938  0.206928  0.210571  0.264078  0.358327\n",
      "neural_16_8_pdgd_informational_16_query_prune_0.5   9.0  0.509138  0.065940  0.388021  0.477778  0.494213  0.539130  0.604099    9.0  0.348773  0.065132  0.281867  0.291626  0.342232  0.370509  0.459924\n",
      "neural_16_8_pdgd_navigational_16_query_prune_0.5    9.0  0.468145  0.035320  0.395313  0.457237  0.467872  0.482623  0.519141    9.0  0.150522  0.013722  0.137439  0.139699  0.142417  0.160678  0.175730\n",
      "random_informational_16_query                      18.0  0.513208  0.076376  0.318517  0.466536  0.507252  0.560158  0.639914   18.0  0.360989  0.068418  0.236002  0.325800  0.357300  0.400318  0.500907\n",
      "random_navigational_16_query                       18.0  0.505906  0.057330  0.409989  0.457676  0.506468  0.552208  0.591890   18.0  0.160120  0.030364  0.122621  0.136754  0.150035  0.178173  0.225789\n"
     ]
    }
   ],
   "source": [
    "# PDGD: multiple queries, random order, gradient pruning\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [1, 4, 8, 12, 16]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "prune_pct = [0.1, 0.3, 0.5, 0.7, 0.9, 0.99]\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, model_name, grouped_data, click_model, click_model_name, num_query):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        if len(relevances) == 1:\n",
    "            continue\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    if len(grouped_train_data) < 1:\n",
    "        return\n",
    "\n",
    "    raw_target = train(\n",
    "        model,\n",
    "        params,\n",
    "        random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "        local_lr,\n",
    "    )\n",
    "    raw_target_abs = raw_target.abs()\n",
    "\n",
    "    for pct in prune_pct:\n",
    "        target = raw_target * (raw_target_abs >= raw_target_abs.quantile(pct))\n",
    "        target = (target - params * (target != 0.0)) / local_lr\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: (train(\n",
    "                model,\n",
    "                params,\n",
    "                [\n",
    "                    (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                    for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "                ],\n",
    "                local_lr,\n",
    "            ) - params) / local_lr,\n",
    "            target,\n",
    "            indices[-1][1],\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "\n",
    "        metrics.update(\n",
    "            f\"{model_name}_{click_model_name}_{num_query}_query_prune_{pct}\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "        # Random guess\n",
    "        random_preds_raw = torch.rand(preds_raw.shape)\n",
    "        random_preds = random_preds_raw.round()\n",
    "        metrics.update(\n",
    "            f\"random_{click_model_name}_{num_query}_query\",\n",
    "            interactions,\n",
    "            random_preds,\n",
    "            preds_raw=random_preds_raw,\n",
    "        )\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    query_ids = data.get_all_query_ids()\n",
    "    query_ids = random.sample(query_ids, len(query_ids))    \n",
    "\n",
    "    for num_query in num_query_per_user:\n",
    "        print(\"Num query\", num_query)\n",
    "        for qids in tqdm(grouper(query_ids, num_query, incomplete=\"ignore\"), total=len(query_ids)//num_query):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    simulate_attack(model, model_name, grouped_data, click_model, click_model_name, num_query)\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())\n",
    "# metrics.save(\"../output/ltr_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation for multiple queries + DP\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [4, 8, 12, 16]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "epsilons = [math.inf]\n",
    "delta = 1e-08\n",
    "sensitivity = 4.0\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, model_name, grouped_data, click_model, epsilons, click_model_name, num_query):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        if len(relevances) == 1:\n",
    "            continue\n",
    "        features = torch.Tensor(features)\n",
    "        # features = torch.column_stack((features, torch.ones(features.shape[0])))\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    if len(grouped_train_data) < 1:\n",
    "        return\n",
    "    \n",
    "    n_batch = len(grouped_train_data)\n",
    "    n_feature_keep = num_features // n_batch\n",
    "    for i in range(n_batch):\n",
    "        features = grouped_train_data[i][0]\n",
    "        features[:,:(i * n_feature_keep)].zero_()\n",
    "        features[:,((i + 1) * n_feature_keep):].zero_()\n",
    "    \n",
    "    raw_target = train(\n",
    "        model,\n",
    "        params,\n",
    "        random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "        local_lr,\n",
    "    )\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        target = (apply_gaussian_mechanism(raw_target, epsilon, delta, sensitivity) - params) / local_lr\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: (train(\n",
    "                model,\n",
    "                params,\n",
    "                [\n",
    "                    (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                    for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "                ],\n",
    "                local_lr,\n",
    "            ) - params) / local_lr,\n",
    "            target,\n",
    "            indices[-1][1],\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "\n",
    "        metrics.update(\n",
    "            f\"{model_name}_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    query_ids = data.get_all_query_ids()\n",
    "    query_ids = random.sample(query_ids, len(query_ids))    \n",
    "\n",
    "    for num_query in num_query_per_user:\n",
    "        print(\"Num query\", num_query)\n",
    "        for qids in tqdm(grouper(query_ids, num_query, incomplete=\"ignore\"), total=len(query_ids)//num_query):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    simulate_attack(model, model_name, grouped_data, click_model, epsilons, click_model_name, num_query)\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())\n",
    "# metrics.save(\"../output/ltr_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation for multiple queries + Pruning\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [4, 8, 12, 16]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "prune_pct = [0.1, 0.3, 0.5, 0.7, 0.9, 0.99]\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, model_name, grouped_data, click_model, click_model_name, num_query):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        if len(relevances) == 1:\n",
    "            continue\n",
    "        features = torch.Tensor(features)\n",
    "        # features = torch.column_stack((features, torch.ones(features.shape[0])))\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    if len(grouped_train_data) < 1:\n",
    "        return\n",
    "    \n",
    "    n_batch = len(grouped_train_data)\n",
    "    n_feature_keep = num_features // n_batch\n",
    "    for i in range(n_batch):\n",
    "        features = grouped_train_data[i][0]\n",
    "        features[:,:(i * n_feature_keep)].zero_()\n",
    "        features[:,((i + 1) * n_feature_keep):].zero_()\n",
    "    \n",
    "    raw_target = train(\n",
    "        model,\n",
    "        params,\n",
    "        random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "        local_lr,\n",
    "    )\n",
    "    raw_target_abs = raw_target.abs()\n",
    "\n",
    "    for pct in prune_pct:\n",
    "        target = raw_target * (raw_target_abs >= raw_target_abs.quantile(pct))\n",
    "        target = (target - params * (target != 0.0)) / local_lr\n",
    "        \n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: (train(\n",
    "                model,\n",
    "                params,\n",
    "                [\n",
    "                    (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                    for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "                ],\n",
    "                local_lr,\n",
    "            ) - params) / local_lr,\n",
    "            target,\n",
    "            indices[-1][1],\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "\n",
    "        metrics.update(\n",
    "            f\"{model_name}_{click_model_name}_{num_query}_query_prune_{pct}\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    query_ids = data.get_all_query_ids()\n",
    "    query_ids = random.sample(query_ids, len(query_ids))    \n",
    "\n",
    "    for num_query in num_query_per_user:\n",
    "        print(\"Num query\", num_query)\n",
    "        for qids in tqdm(grouper(query_ids, num_query, incomplete=\"ignore\"), total=len(query_ids)//num_query):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    simulate_attack(model, model_name, grouped_data, click_model, click_model_name, num_query)\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())\n",
    "# metrics.save(\"../output/ltr_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
