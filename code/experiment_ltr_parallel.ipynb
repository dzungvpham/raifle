{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from attack import (\n",
    "    reconstruct_interactions,\n",
    ")\n",
    "from dataset import (\n",
    "    LearningToRankDataset,\n",
    ")\n",
    "from more_itertools import grouper\n",
    "from ranker import (\n",
    "    LinearPDGDRanker,\n",
    "    Neural1LayerPDGDRanker,\n",
    "    Neural2LayerPDGDRanker,\n",
    ")\n",
    "from scipy.stats import ks_2samp\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import (\n",
    "    CascadeClickModel,\n",
    "    Metrics,\n",
    "    apply_gaussian_mechanism,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    torch.manual_seed(2023)\n",
    "    random.seed(2023)\n",
    "    np.random.seed(2023)\n",
    "\n",
    "# Make sure to normalize if using MSLR\n",
    "data = LearningToRankDataset(\"../dataset/MQ2008/Fold1/test.txt\", normalize=False)\n",
    "num_features = data.get_num_features()\n",
    "\n",
    "models = {\n",
    "    \"linear_pdgd\": LinearPDGDRanker(num_features),\n",
    "    # \"neural_4_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=4),\n",
    "    # \"neural_8_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=8),\n",
    "    # \"neural_16_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=16),\n",
    "    # \"neural_4_2_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=4, hidden_size2=2\n",
    "    # ),\n",
    "    # \"neural_8_4_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=8, hidden_size2=4\n",
    "    # ),\n",
    "    # \"neural_16_8_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=16, hidden_size2=8\n",
    "    # ),\n",
    "}\n",
    "\n",
    "click_models = {\n",
    "    # \"perfect\": CascadeClickModel(prob_click=[0.0, 0.5, 1.0], prob_stop=[0.0, 0.0, 0.0]),\n",
    "    \"navigational\": CascadeClickModel(\n",
    "        prob_click=[0.05, 0.5, 0.95], prob_stop=[0.2, 0.5, 0.9]\n",
    "    ),\n",
    "    \"informational\": CascadeClickModel(\n",
    "        prob_click=[0.4, 0.7, 0.9], prob_stop=[0.1, 0.3, 0.5]\n",
    "    ),\n",
    "}\n",
    "\n",
    "# MSLR Click Model\n",
    "# click_models = {\n",
    "#     \"perfect\": CascadeClickModel(\n",
    "#         prob_click=[0.0, 0.2, 0.4, 0.8, 1.0], prob_stop=[0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "#     ),\n",
    "#     \"navigational\": CascadeClickModel(\n",
    "#         prob_click=[0.05, 0.3, 0.5, 0.7, 0.95], prob_stop=[0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "#     ),\n",
    "#     \"informational\": CascadeClickModel(\n",
    "#         prob_click=[0.4, 0.6, 0.7, 0.8, 0.9], prob_stop=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#     ),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: multiple queries, random order, DP\n",
    "\n",
    "def worker(num_query):\n",
    "    set_seed(num_query)\n",
    "\n",
    "    data = LearningToRankDataset(\"../dataset/MQ2008/Fold1/test.txt\", normalize=False)\n",
    "    \n",
    "    num_item_per_ranking = 10\n",
    "    local_lr = 1e-01\n",
    "\n",
    "    num_sim_round = 1\n",
    "    atk_lr = 1e-01\n",
    "    max_iter = 1000\n",
    "    num_atk = 1\n",
    "\n",
    "    epsilons = [1.0, 10.0, 100.0, math.inf]\n",
    "    delta = 1e-08\n",
    "    sensitivity = 4.0\n",
    "\n",
    "    metrics = Metrics()\n",
    "\n",
    "    def train(model, params, grouped_train_data, local_lr):\n",
    "        cur_params = params.clone()\n",
    "\n",
    "        for features, ranking, interactions in grouped_train_data:\n",
    "            cur_grad = model.grad(\n",
    "                cur_params,\n",
    "                features,\n",
    "                ranking,\n",
    "                interactions,\n",
    "            )\n",
    "\n",
    "            cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "        return cur_params\n",
    "\n",
    "\n",
    "    def simulate_attack(model, grouped_data, click_model, epsilons, click_model_name, num_query):\n",
    "        params = model.gen_params()\n",
    "\n",
    "        grouped_train_data = []\n",
    "        indices = []\n",
    "        start_ind = 0\n",
    "        for relevances, features in grouped_data:\n",
    "            if len(relevances) == 1:\n",
    "                continue\n",
    "            features = torch.Tensor(features)\n",
    "            ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "            features = features[ranking]\n",
    "            interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "            # Remap the original ranking into the correct range\n",
    "            _, ranking = torch.where(\n",
    "                torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "            )\n",
    "            grouped_train_data.append((features, ranking, interactions))\n",
    "            indices.append((start_ind, start_ind + len(ranking)))\n",
    "            start_ind += len(ranking)\n",
    "\n",
    "        if len(grouped_train_data) < 1:\n",
    "            return\n",
    "\n",
    "        raw_target = train(\n",
    "            model,\n",
    "            params,\n",
    "            random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "            local_lr,\n",
    "        )\n",
    "\n",
    "        for epsilon in epsilons:\n",
    "            target = (apply_gaussian_mechanism(raw_target, epsilon, delta, sensitivity) - params) / local_lr\n",
    "\n",
    "            preds_raw, _ = reconstruct_interactions(\n",
    "                lambda I: (train(\n",
    "                    model,\n",
    "                    params,\n",
    "                    [\n",
    "                        (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                        for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "                    ],\n",
    "                    local_lr,\n",
    "                ) - params) / local_lr,\n",
    "                target,\n",
    "                indices[-1][1],\n",
    "                lr=atk_lr,\n",
    "                max_iter=max_iter,\n",
    "                num_rounds=num_atk,\n",
    "                return_raw=True,\n",
    "            )\n",
    "            preds = preds_raw.sigmoid().round().long()\n",
    "            interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "\n",
    "            metrics.update(\n",
    "                f\"{model_name}_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "                interactions,\n",
    "                preds,\n",
    "                preds_raw=preds_raw,\n",
    "            )\n",
    "\n",
    "            # Random guess\n",
    "            random_preds_raw = torch.rand(preds_raw.shape)\n",
    "            random_preds = random_preds_raw.round()\n",
    "            metrics.update(\n",
    "                f\"random_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "                interactions,\n",
    "                random_preds,\n",
    "                preds_raw=random_preds_raw,\n",
    "            )\n",
    "\n",
    "    for _ in tqdm(range(num_sim_round)):\n",
    "        query_ids = data.get_all_query_ids()\n",
    "        query_ids = random.sample(query_ids, len(query_ids))    \n",
    "        for qids in tqdm(grouper(query_ids, num_query, incomplete=\"ignore\"), total=len(query_ids)//num_query):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    simulate_attack(model, grouped_data, click_model, epsilons, click_model_name, num_query)\n",
    "\n",
    "    metrics.save(f\"../output/ltr_{num_query}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_query_per_user = [1, 4, 8, 12, 16]\n",
    "    pool = Pool()\n",
    "    metrics = pool.map(worker, num_query_per_user)\n",
    "    final_metrics_df = pd.concat([m.df for m in metrics])\n",
    "    final_metrics_df.to_csv(f\"../output/ltr_output_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
